{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3bc67b-3c18-43c5-ad0b-f41b418807a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T16:04:16.048543280Z",
     "start_time": "2023-11-19T16:04:15.819653370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaModel were not initialized from the model checkpoint at stas/tiny-random-llama-2 and are newly initialized: ['model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "token = \"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\"\n",
    "\n",
    "model = \"hf_stas/tiny-random-llama-2\"\n",
    "# model = \"hf_lmsys/vicuna-7b-v1.3\"\n",
    "model = model.split(\"_\")[-1]\n",
    "\n",
    "full_model = AutoModel.from_pretrained(model\n",
    "                                       , output_hidden_states=True,\n",
    "                                       use_auth_token='',\n",
    "                                      )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model,\n",
    "                                          token=''\n",
    "                                          # , use_auth_token=token\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa72ac7c-1022-49a9-a46c-e45206656700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T16:04:16.817000538Z",
     "start_time": "2023-11-19T16:04:16.811617681Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_ids = tokenizer(\"hi\", return_tensors='pt')[\"input_ids\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[  1, 229, 153, 132, 107, 108]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"hi\", return_tensors='pt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T16:04:33.492438970Z",
     "start_time": "2023-11-19T16:04:33.449544903Z"
    }
   },
   "id": "e521a699cb2c929d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d064a2-06af-4721-a116-6260159e8761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:49:54.248609931Z",
     "start_time": "2023-11-19T15:49:54.243055578Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding = full_model(seq_ids)[\"last_hidden_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6bc6c215-aac4-4d18-923f-e28ab2e25d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:34:20.714622526Z",
     "start_time": "2023-11-19T13:34:20.636657557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_model(seq_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "985aac94e1dedc10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:34:20.968732477Z",
     "start_time": "2023-11-19T13:34:20.957317194Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_model(seq_ids).last_hidden_state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80569154830341ff",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T15:50:27.048466117Z",
     "start_time": "2023-11-19T15:50:27.004596144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(6, 16)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model(seq_ids).last_hidden_state[0].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bddbce0e-d611-4334-aafc-3a683c0a4a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:34:22.307426456Z",
     "start_time": "2023-11-19T13:34:22.305561098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last_hidden_state', 'past_key_values', 'hidden_states']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(full_model(seq_ids).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68eadfa8-e6ce-413d-a02c-b72be1666692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:50:42.395367305Z",
     "start_time": "2023-11-19T15:50:42.347894973Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding = full_model(seq_ids)[\"last_hidden_state\"].mean(axis=[0,1]).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.3220,  0.2277,  1.0253,  0.4318, -0.1543,  0.3265, -0.0627,  0.1382,\n         0.2769, -0.2701, -0.7543,  0.2692,  0.2671,  0.3833,  0.1777, -0.0613],\n       grad_fn=<MeanBackward1>)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model(seq_ids)[\"last_hidden_state\"].mean(axis=[0, 1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T15:53:11.988401597Z",
     "start_time": "2023-11-19T15:53:11.947215499Z"
    }
   },
   "id": "2dda99a972aa0439"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4da4d8dc-b325-40c0-afaa-570f2c9f160d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T15:58:14.817876629Z",
     "start_time": "2023-11-19T15:58:14.769490844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([[0.8830, 1.2890, 1.4374, 1.9147, 0.1934, 1.0196, 1.5842, 1.8089, 2.1782,\n         0.5392, 0.3511, 2.8626, 0.8909, 1.6265, 1.5099, 0.7303]],\n       grad_fn=<MaxBackward0>),\nindices=tensor([[5, 1, 2, 0, 5, 4, 1, 4, 5, 3, 1, 2, 0, 5, 0, 2]]))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model(seq_ids)[\"last_hidden_state\"].max(axis=1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b64bfe0-3d4d-4bb0-a982-a11d05024d4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:19:37.547377542Z",
     "start_time": "2023-11-19T11:19:37.539256129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1176, -0.5227,  0.7872,  1.9147,  0.1836,  0.2644,  0.2650,\n",
       "          -0.3453, -0.2523, -1.4493, -2.0100,  0.0400,  0.8909,  0.5693,\n",
       "           1.5099,  0.0061],\n",
       "         [-0.1771,  1.2890,  1.1390,  1.5421, -0.4276,  0.8708,  1.5842,\n",
       "          -0.9612,  0.2046,  0.4822,  0.3511, -1.1898,  0.8283, -0.5328,\n",
       "           1.2452, -1.2789],\n",
       "         [ 0.6879, -0.1596,  1.4374,  0.7793,  0.1343, -0.5861, -1.0100,\n",
       "          -0.6172,  0.0451,  0.3053, -0.2175,  2.8626,  0.6230,  0.1501,\n",
       "          -1.2365,  0.7303],\n",
       "         [-1.6715,  0.3689,  0.9377,  0.1156, -0.4611,  0.8296, -0.5593,\n",
       "           1.1896,  1.2797,  0.5392, -2.3945, -0.3266,  0.6564, -0.9172,\n",
       "          -0.2626, -0.1163],\n",
       "         [-0.5368,  0.7225,  0.4267, -0.1495, -0.5483,  1.0196, -1.0024,\n",
       "           1.8089, -1.7940, -1.3499, -0.1630, -0.9501, -0.6590,  1.4036,\n",
       "          -0.0968,  0.5737],\n",
       "         [ 0.8830, -0.3320,  1.4241, -1.6115,  0.1934, -0.4392,  0.3459,\n",
       "          -0.2458,  2.1782, -0.1479, -0.0917,  1.1791, -0.7370,  1.6265,\n",
       "          -0.0931, -0.2827]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model(seq_ids)[\"last_hidden_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67bc383c-3b82-423f-84d8-820c0cf7cf3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:28:06.101911796Z",
     "start_time": "2023-11-19T11:28:04.612870695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaModel were not initialized from the model checkpoint at stas/tiny-random-llama-2 and are newly initialized: ['model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "gen_pipe = pipeline(\n",
    "            \"feature-extraction\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device='cuda:0'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2defa1805290c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:28:39.285925575Z",
     "start_time": "2023-11-19T11:28:38.225624661Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-1.1175556182861328,\n",
       "   -0.5226937532424927,\n",
       "   0.7871804237365723,\n",
       "   1.9146766662597656,\n",
       "   0.18356014788150787,\n",
       "   0.26437053084373474,\n",
       "   0.2650412619113922,\n",
       "   -0.34527406096458435,\n",
       "   -0.2523225247859955,\n",
       "   -1.449312686920166,\n",
       "   -2.009962320327759,\n",
       "   0.0399501770734787,\n",
       "   0.8908973932266235,\n",
       "   0.5693443417549133,\n",
       "   1.50994873046875,\n",
       "   0.006138209253549576],\n",
       "  [-0.17712020874023438,\n",
       "   1.289019227027893,\n",
       "   1.1389769315719604,\n",
       "   1.5420831441879272,\n",
       "   -0.42755013704299927,\n",
       "   0.8707579970359802,\n",
       "   1.5841963291168213,\n",
       "   -0.9612216949462891,\n",
       "   0.20458737015724182,\n",
       "   0.4821988344192505,\n",
       "   0.3510575592517853,\n",
       "   -1.1897553205490112,\n",
       "   0.8282694816589355,\n",
       "   -0.5327813029289246,\n",
       "   1.245207667350769,\n",
       "   -1.2788676023483276],\n",
       "  [0.687866747379303,\n",
       "   -0.15962690114974976,\n",
       "   1.437384843826294,\n",
       "   0.7793460488319397,\n",
       "   0.1342785507440567,\n",
       "   -0.5860916376113892,\n",
       "   -1.0099701881408691,\n",
       "   -0.6171806454658508,\n",
       "   0.04508574306964874,\n",
       "   0.30527830123901367,\n",
       "   -0.21753385663032532,\n",
       "   2.862614393234253,\n",
       "   0.6229836940765381,\n",
       "   0.15005071461200714,\n",
       "   -1.236494779586792,\n",
       "   0.7303139567375183],\n",
       "  [-1.6714961528778076,\n",
       "   0.36892959475517273,\n",
       "   0.9376826882362366,\n",
       "   0.11557504534721375,\n",
       "   -0.46109288930892944,\n",
       "   0.8295906186103821,\n",
       "   -0.5592636466026306,\n",
       "   1.1895833015441895,\n",
       "   1.2796777486801147,\n",
       "   0.5391883254051208,\n",
       "   -2.394456148147583,\n",
       "   -0.3265783488750458,\n",
       "   0.6563618779182434,\n",
       "   -0.9171837568283081,\n",
       "   -0.2625900208950043,\n",
       "   -0.1162627637386322],\n",
       "  [-0.5368314385414124,\n",
       "   0.7224996089935303,\n",
       "   0.42672863602638245,\n",
       "   -0.14949248731136322,\n",
       "   -0.5482993721961975,\n",
       "   1.0196107625961304,\n",
       "   -1.0023964643478394,\n",
       "   1.808907151222229,\n",
       "   -1.7939553260803223,\n",
       "   -1.3499305248260498,\n",
       "   -0.16297806799411774,\n",
       "   -0.9501187205314636,\n",
       "   -0.6589928865432739,\n",
       "   1.4036234617233276,\n",
       "   -0.09682448953390121,\n",
       "   0.5736925005912781],\n",
       "  [0.883038341999054,\n",
       "   -0.3319947421550751,\n",
       "   1.4241271018981934,\n",
       "   -1.611451268196106,\n",
       "   0.19338317215442657,\n",
       "   -0.43919339776039124,\n",
       "   0.345903605222702,\n",
       "   -0.24582886695861816,\n",
       "   2.1782360076904297,\n",
       "   -0.1479114592075348,\n",
       "   -0.09171158075332642,\n",
       "   1.1790529489517212,\n",
       "   -0.7369651794433594,\n",
       "   1.6264899969100952,\n",
       "   -0.09313464909791946,\n",
       "   -0.2827090620994568]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_pipe(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9aa025595004b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:29:34.405Z",
     "start_time": "2023-11-19T11:29:34.398684508Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_pipe(\"hi\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3098d7fadb74912b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:54:41.208912662Z",
     "start_time": "2023-11-19T11:54:41.199749173Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3260125745ad52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:55:29.748488537Z",
     "start_time": "2023-11-19T13:55:29.648125668Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhf_stas/tiny-random-llama-2\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m----> 4\u001B[0m full_model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModel\u001B[49m\u001B[38;5;241m.\u001B[39mfrom_pretrained(model\n\u001B[1;32m      5\u001B[0m                                        , output_hidden_states\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      6\u001B[0m                                        \u001B[38;5;66;03m# , use_auth_token=token\u001B[39;00m\n\u001B[1;32m      7\u001B[0m                                        device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      8\u001B[0m                                       )\n\u001B[1;32m      9\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model\n\u001B[1;32m     10\u001B[0m                                           \u001B[38;5;66;03m# , use_auth_token=token\u001B[39;00m\n\u001B[1;32m     11\u001B[0m                                          )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'AutoModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = \"hf_stas/tiny-random-llama-2\"\n",
    "model = model.split(\"_\")[-1]\n",
    "\n",
    "full_model = AutoModel.from_pretrained(model\n",
    "                                       , output_hidden_states=True,\n",
    "                                       # , use_auth_token=token\n",
    "                                       device='cuda:0'\n",
    "                                      )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model\n",
    "                                          # , use_auth_token=token\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3dffe8e579252fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:54:42.723177469Z",
     "start_time": "2023-11-19T11:54:42.714993959Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_ids = tokenizer(\"Hey Tutor! What is Data Science?\", return_tensors='pt')[\"input_ids\"]\n",
    "embedding = full_modelDEFAULT_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    ".detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a237f995d7d59ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:54:45.179833324Z",
     "start_time": "2023-11-19T11:54:45.172407340Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_model(seq_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ab83d90bdd201be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:54:46.211155249Z",
     "start_time": "2023-11-19T11:54:46.203085763Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 46, 16)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model(seq_ids)['last_hidden_state'].detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "256d6b96042b1eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:54:48.669093606Z",
     "start_time": "2023-11-19T11:54:48.660115741Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fm_vec = full_model(seq_ids).last_hidden_state[0].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5cccbaaac4becad9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:54:54.620919325Z",
     "start_time": "2023-11-19T11:54:54.576494937Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 16)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35408765ff00e5c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:54:57.073945576Z",
     "start_time": "2023-11-19T11:54:56.946794202Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaModel were not initialized from the model checkpoint at stas/tiny-random-llama-2 and are newly initialized: ['model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "gen_pipe = pipeline(\n",
    "            \"feature-extraction\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device='cuda:0'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a377e2c11b1a007a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:58:11.170435586Z",
     "start_time": "2023-11-19T11:58:11.139100741Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gp_vec = np.array(gen_pipe(\"Hey Tutor! What is Data Science?\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e615fc3e2de783ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:58:05.948264277Z",
     "start_time": "2023-11-19T11:58:05.920804540Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 46, 16)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b382ab9b7992827a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:55:06.599813014Z",
     "start_time": "2023-11-19T11:55:06.595817322Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fm_vec.reshape(1, -1), gp_vec.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1027fb8687306175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:55:02.030689348Z",
     "start_time": "2023-11-19T11:55:02.023447011Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 16)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3648be7e2734086f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T11:54:09.552034654Z",
     "start_time": "2023-11-19T11:54:09.548416939Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 16)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d16c839e2ebee14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T12:32:48.832869062Z",
     "start_time": "2023-11-19T12:32:48.828902654Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stas/tiny-random-llama-2'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc87b753cd5ded9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T12:31:53.279764227Z",
     "start_time": "2023-11-19T12:31:52.040104832Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6eb0bf649dbaf982",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T12:34:22.269106459Z",
     "start_time": "2023-11-19T12:34:19.017896595Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1dbbd74faf4decb4724600909db140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae7d6867518440d8459269ae0b0db24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d5ac09ec834250a1b6ef97da9a8fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/680 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d555dab9ad0b4489b3ee60df742bb7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6895925fe4ad46dc966489c81b6e94da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading make_tiny_model.py:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18e5d59b57e4c038b2c46a468c8acd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/211k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f3069a37d148ffb7766cd7171f8667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84cceb9b1c84d89899dc10b86d09d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/64.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9a38a34aee4691ba7a9721f7f648d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d7f4dd08a948ec85abf870efe86c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/918 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/reventh/.cache/torch/sentence_transformers/stas_tiny-random-llama-2. Creating a new one with MEAN pooling.\n",
      "Some weights of LlamaModel were not initialized from the model checkpoint at /home/reventh/.cache/torch/sentence_transformers/stas_tiny-random-llama-2 and are newly initialized: ['model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "                model_name=model,\n",
    "                model_kwargs={\"device\": \"cuda:0\"                 \n",
    "                },\n",
    "                encode_kwargs={'normalize_embeddings': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "30e6723aa261486b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T12:34:58.448604680Z",
     "start_time": "2023-11-19T12:34:58.158474381Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[95], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43membedding_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_query\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHey Tutor! What is Data Science?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/langchain/embeddings/huggingface.py:103\u001B[0m, in \u001B[0;36mHuggingFaceEmbeddings.embed_query\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21membed_query\u001B[39m(\u001B[38;5;28mself\u001B[39m, text: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[1;32m     95\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \n\u001B[1;32m     97\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;124;03m        Embeddings for the text.\u001B[39;00m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/langchain/embeddings/huggingface.py:90\u001B[0m, in \u001B[0;36mHuggingFaceEmbeddings.embed_documents\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m     88\u001B[0m     sentence_transformers\u001B[38;5;241m.\u001B[39mSentenceTransformer\u001B[38;5;241m.\u001B[39mstop_multi_process_pool(pool)\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 90\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m embeddings\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:161\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m start_index \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(sentences), batch_size, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBatches\u001B[39m\u001B[38;5;124m\"\u001B[39m, disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m show_progress_bar):\n\u001B[1;32m    160\u001B[0m     sentences_batch \u001B[38;5;241m=\u001B[39m sentences_sorted[start_index:start_index\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[0;32m--> 161\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentences_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    162\u001B[0m     features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:319\u001B[0m, in \u001B[0;36mSentenceTransformer.tokenize\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtokenize\u001B[39m(\u001B[38;5;28mself\u001B[39m, texts: Union[List[\u001B[38;5;28mstr\u001B[39m], List[Dict], List[Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]]]):\n\u001B[1;32m    316\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;124;03m    Tokenizes the texts\u001B[39;00m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 319\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_first_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:113\u001B[0m, in \u001B[0;36mTransformer.tokenize\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdo_lower_case:\n\u001B[1;32m    111\u001B[0m     to_tokenize \u001B[38;5;241m=\u001B[39m [[s\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m col] \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m to_tokenize]\n\u001B[0;32m--> 113\u001B[0m output\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mto_tokenize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlongest_first\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2577\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2575\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[1;32m   2576\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[0;32m-> 2577\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mall_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2578\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2579\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2663\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2658\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2659\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch length of `text`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not match batch length of `text_pair`:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2660\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text_pair)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2661\u001B[0m         )\n\u001B[1;32m   2662\u001B[0m     batch_text_or_text_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(text, text_pair)) \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m text\n\u001B[0;32m-> 2663\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2664\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2665\u001B[0m \u001B[43m        \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2666\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2667\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2669\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2673\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2679\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2680\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2681\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2682\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2683\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[1;32m   2684\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[1;32m   2685\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2701\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2702\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2845\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2828\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2829\u001B[0m \u001B[38;5;124;03mTokenize and prepare for the model a list of sequences or a list of pairs of sequences.\u001B[39;00m\n\u001B[1;32m   2830\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2841\u001B[0m \u001B[38;5;124;03m        details in `encode_plus`).\u001B[39;00m\n\u001B[1;32m   2842\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2844\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[0;32m-> 2845\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_padding_truncation_strategies\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2848\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2849\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2850\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2851\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2852\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2854\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_encode_plus(\n\u001B[1;32m   2855\u001B[0m     batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[1;32m   2856\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2871\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2872\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/lmtutor/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2482\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001B[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2480\u001B[0m \u001B[38;5;66;03m# Test if we have a padding token\u001B[39;00m\n\u001B[1;32m   2481\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m padding_strategy \u001B[38;5;241m!=\u001B[39m PaddingStrategy\u001B[38;5;241m.\u001B[39mDO_NOT_PAD \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_token \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_token_id \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m-> 2482\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2483\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2484\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2485\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpad_token\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[PAD]\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m})`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2486\u001B[0m     )\n\u001B[1;32m   2488\u001B[0m \u001B[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001B[39;00m\n\u001B[1;32m   2489\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   2490\u001B[0m     truncation_strategy \u001B[38;5;241m!=\u001B[39m TruncationStrategy\u001B[38;5;241m.\u001B[39mDO_NOT_TRUNCATE\n\u001B[1;32m   2491\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m padding_strategy \u001B[38;5;241m!=\u001B[39m PaddingStrategy\u001B[38;5;241m.\u001B[39mDO_NOT_PAD\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2494\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (max_length \u001B[38;5;241m%\u001B[39m pad_to_multiple_of \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m   2495\u001B[0m ):\n",
      "\u001B[0;31mValueError\u001B[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
     ]
    }
   ],
   "source": [
    "embedding_model.embed_query(\"Hey Tutor! What is Data Science?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7273d62d06f7e3f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T12:59:49.562262042Z",
     "start_time": "2023-11-19T12:59:49.556767960Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func(**kwargs):\n",
    "    if 'a' in kwargs:\n",
    "        print(kwargs['a'])\n",
    "    print(sum(kwargs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "59609908836822cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T12:59:50.203349980Z",
     "start_time": "2023-11-19T12:59:50.157260548Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "func(a=1, b=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a7d6eaf1af83d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:22:54.828649149Z",
     "start_time": "2023-11-19T13:22:54.786957490Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1, 229, 153, 132,  75, 104, 124, 229, 153, 132,  87, 120, 119, 114,\n",
       "         117,  36, 229, 153, 132,  90, 107, 100, 119, 229, 153, 132, 108, 118,\n",
       "         229, 153, 132,  71, 100, 119, 100, 229, 153, 132,  86, 102, 108, 104,\n",
       "         113, 102, 104,  66]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hey Tutor! What is Data Science?\", return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "484c073aa8dccf7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:27:14.588292373Z",
     "start_time": "2023-11-19T13:27:14.545309193Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DEFAULT_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e5d3f8691b30ee0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:34:55.392390326Z",
     "start_time": "2023-11-19T13:34:55.351447721Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7081ec1aeb32c331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:34:56.705434040Z",
     "start_time": "2023-11-19T13:34:55.984445584Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sentence_transformers.SentenceTransformer(DEFAULT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "38c8421c6211e923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-19T13:34:56.811363222Z",
     "start_time": "2023-11-19T13:34:56.700036220Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(\"Hey Tutor! What is Data Science?\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e2c925bc64d24c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T16:05:20.265597421Z",
     "start_time": "2023-11-19T16:05:19.024079482Z"
    }
   },
   "outputs": [],
   "source": [
    "from model.llm_encoder import LLMBasedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f532f850541f32ed",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T16:05:22.272535200Z",
     "start_time": "2023-11-19T16:05:20.518598608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reventh/anaconda3/envs/lmtutor/lib/python3.9/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Some weights of LlamaModel were not initialized from the model checkpoint at stas/tiny-random-llama-2 and are newly initialized: ['model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "llmmodel = LLMBasedEmbeddings(\"stas/tiny-random-llama-2\", aggr='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c512f1ce9c00c95f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T16:05:22.384364977Z",
     "start_time": "2023-11-19T16:05:22.341826543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[array([-0.10889034,  0.05917635,  0.35102242,  0.46370503, -0.0371076 ,\n         0.06390191, -0.14735016, -0.09830719,  0.19880925,  0.15226689,\n        -0.3408267 ,  0.21463007,  0.36214927, -0.20361033,  0.13497443,\n         0.03197159], dtype=float32),\n array([-0.10889034,  0.05917635,  0.35102242,  0.46370503, -0.0371076 ,\n         0.06390191, -0.14735016, -0.09830719,  0.19880925,  0.15226689,\n        -0.3408267 ,  0.21463007,  0.36214927, -0.20361033,  0.13497443,\n         0.03197159], dtype=float32)]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmmodel.embed_documents([\"Hey Tutor! What is Data Science?\", \"Hey Tutor! What is Data Science?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dbf22243df70f637"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
